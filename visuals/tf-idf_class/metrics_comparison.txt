=== Text-Only Model Metrics ===
Accuracy: 0.9886
F1 Score: 0.9889
ROC-AUC: 0.9990

Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.97      0.98        30
           1       1.00      1.00      1.00        28
           2       0.97      1.00      0.98        30

    accuracy                           0.99        88
   macro avg       0.99      0.99      0.99        88
weighted avg       0.99      0.99      0.99        88
