{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryamantepal/anaconda3/envs/salesforce/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Availability DownTime Duration in hours',\n",
       "       'Count of Customers Affected', 'Regions Affected'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "availability_data = pd.read_csv('/Users/aryamantepal/Documents/programs/Breakthrough Tech AI MIT/AI Studio/Customer_Sentiment_Analysis/Datasets/AvailabilityData.csv', sep=\"\\t\")\n",
    "\n",
    "availability_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:38:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:38:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "availability_data['Date'] = pd.to_datetime(availability_data['Date'])\n",
    "\n",
    "prophet_df = availability_data.rename(columns={\n",
    "    'Date': 'ds', \n",
    "    'Availability DownTime Duration in hours': 'y'\n",
    "})\n",
    "\n",
    "model = Prophet(\n",
    "    changepoint_prior_scale=0.05,  \n",
    "    seasonality_prior_scale=10,  \n",
    "    holidays_prior_scale=10        \n",
    ")\n",
    "\n",
    "model.add_regressor('Count of Customers Affected')\n",
    "model.add_regressor('Downtime_Severity')\n",
    "\n",
    "prophet_df['Downtime_Severity'] = availability_data['Availability DownTime Duration in hours'] / availability_data['Count of Customers Affected']\n",
    "\n",
    "model.fit(prophet_df)\n",
    "\n",
    "future = model.make_future_dataframe(periods=30)  \n",
    "future['Count of Customers Affected'] = np.concatenate([\n",
    "    availability_data['Count of Customers Affected'], \n",
    "    np.full(30, availability_data['Count of Customers Affected'].mean())\n",
    "])\n",
    "future['Downtime_Severity'] = np.concatenate([\n",
    "    prophet_df['Downtime_Severity'], \n",
    "    np.full(30, prophet_df['Downtime_Severity'].mean())\n",
    "])\n",
    "\n",
    "forecast = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryamantepal/anaconda3/envs/salesforce/lib/python3.10/site-packages/prophet/plot.py:228: FutureWarning: The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "  fcst_t = fcst['ds'].dt.to_pydatetime()\n",
      "/Users/aryamantepal/anaconda3/envs/salesforce/lib/python3.10/site-packages/prophet/plot.py:228: FutureWarning: The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "  fcst_t = fcst['ds'].dt.to_pydatetime()\n"
     ]
    }
   ],
   "source": [
    "forecast_components = model.plot_components(forecast)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outreach_timing_components.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_outreach_windows(forecast):\n",
    "    forecast['forecast_lower'] = forecast['yhat_lower']\n",
    "    forecast['forecast_upper'] = forecast['yhat_upper']\n",
    "    \n",
    "    forecast['confidence_interval'] = forecast['forecast_upper'] - forecast['forecast_lower']\n",
    "    \n",
    "    optimal_windows = forecast.nsmallest(5, 'confidence_interval')\n",
    "    \n",
    "    return optimal_windows[['ds', 'yhat', 'forecast_lower', 'forecast_upper', 'confidence_interval']]\n",
    "\n",
    "optimal_outreach_times = analyze_outreach_windows(forecast)\n",
    "\n",
    "def analyze_regional_impact(availability_data):\n",
    "    availability_data['Regions'] = availability_data['Regions Affected'].str.split(', ')\n",
    "    \n",
    "    region_impact = availability_data.explode('Regions')\n",
    "    \n",
    "    region_summary = region_impact.groupby('Regions').agg({\n",
    "        'Availability DownTime Duration in hours': ['mean', 'sum'],\n",
    "        'Count of Customers Affected': ['mean', 'sum']\n",
    "    }).reset_index()\n",
    "    \n",
    "    region_summary.columns = ['Region', 'Avg_Downtime', 'Total_Downtime', 'Avg_Customers_Affected', 'Total_Customers_Affected']\n",
    "    \n",
    "    return region_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Outreach Windows:\n",
      "            ds       yhat  forecast_lower  forecast_upper  confidence_interval\n",
      "82  2024-03-23   9.904582        3.262715       16.567142            13.304427\n",
      "96  2024-04-06  11.978789        5.256149       18.816811            13.560662\n",
      "192 2024-07-11  12.854847        6.508773       20.152142            13.643369\n",
      "119 2024-04-29  13.133115        5.875371       19.548589            13.673219\n",
      "25  2024-01-26   9.599802        2.859184       16.599883            13.740699\n",
      "\n",
      "Regional Impact Summary:\n",
      "      Region  Avg_Downtime  Total_Downtime  Avg_Customers_Affected  \\\n",
      "0  Australia     11.104167             533            24775.208333   \n",
      "1      China     12.038462             626            25284.538462   \n",
      "2     Europe     11.052632             630            29391.578947   \n",
      "3      India     11.333333             612            25425.462963   \n",
      "4      Japan     11.562500             740            22345.296875   \n",
      "5        USA      9.705882             495            24634.470588   \n",
      "\n",
      "   Total_Customers_Affected  \n",
      "0                   1189210  \n",
      "1                   1314796  \n",
      "2                   1675320  \n",
      "3                   1372975  \n",
      "4                   1430099  \n",
      "5                   1256358  \n",
      "\n",
      "Outputs generated:\n",
      "1. optimal_outreach_windows.csv - Detailed optimal outreach windows\n",
      "2. regional_impact_summary.csv - Analysis of regional impacts\n",
      "3. outreach_timing_components.png - Forecast components\n",
      "4. outreach_timing_forecast.png - Forecast visualization\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal Outreach Windows:\")\n",
    "print(optimal_outreach_times)\n",
    "\n",
    "\n",
    "regional_impact = analyze_regional_impact(availability_data)\n",
    "print(\"\\nRegional Impact Summary:\")\n",
    "print(regional_impact)\n",
    "\n",
    "\n",
    "optimal_outreach_times.to_csv('optimal_outreach_windows.csv', index=False)\n",
    "regional_impact.to_csv('regional_impact_summary.csv', index=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(forecast['ds'], forecast['yhat'], label='Predicted Downtime')\n",
    "plt.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], alpha=0.3)\n",
    "plt.title('Predicted Downtime with Confidence Interval')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Predicted Downtime Duration (hours)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('outreach_timing_forecast.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nOutputs generated:\")\n",
    "print(\"1. optimal_outreach_windows.csv - Detailed optimal outreach windows\")\n",
    "print(\"2. regional_impact_summary.csv - Analysis of regional impacts\")\n",
    "print(\"3. outreach_timing_components.png - Forecast components\")\n",
    "print(\"4. outreach_timing_forecast.png - Forecast visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1901108322.py:19: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  company_availability = availability_data[availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Company Name  Average Sentiment  Average Rating Sentiment Quality  \\\n",
      "0         A+ Electronics           7.218365        6.000000              High   \n",
      "1         A+ Investments           7.250509        5.925926              High   \n",
      "2       A Plus Lawn Care           6.748584        5.633333            Medium   \n",
      "3            Access Asia           6.247198        4.862069            Medium   \n",
      "4     Accord Investments           7.495769        6.129032              High   \n",
      "...                  ...                ...             ...               ...   \n",
      "4478              iTunes           6.553560        4.961538            Medium   \n",
      "4479               iiNet           6.310248        4.655172            Medium   \n",
      "4480                resQ           6.375384        4.769231            Medium   \n",
      "4481         ÃcomarchÃ©           6.852584        5.222222            Medium   \n",
      "4482                ÃBB           7.061130        5.192308              High   \n",
      "\n",
      "     Best Outreach Window                               Recommended Approach  \n",
      "0                    None  Immediate outreach recommended. High sentiment...  \n",
      "1                    None  Immediate outreach recommended. High sentiment...  \n",
      "2                    None  Cautious approach needed. Prepare comprehensiv...  \n",
      "3                    None  Cautious approach needed. Prepare comprehensiv...  \n",
      "4                    None  Immediate outreach recommended. High sentiment...  \n",
      "...                   ...                                                ...  \n",
      "4478                 None  Cautious approach needed. Prepare comprehensiv...  \n",
      "4479                 None  Cautious approach needed. Prepare comprehensiv...  \n",
      "4480                 None  Cautious approach needed. Prepare comprehensiv...  \n",
      "4481                 None  Cautious approach needed. Prepare comprehensiv...  \n",
      "4482                 None  Immediate outreach recommended. High sentiment...  \n",
      "\n",
      "[4483 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "feedback_data = pd.read_csv('/Users/aryamantepal/Documents/programs/Breakthrough Tech AI MIT/AI Studio/Customer_Sentiment_Analysis/clean-data/feedback_data_with_sentiment.csv', sep=\",\")\n",
    "leads_data = pd.read_csv('/Users/aryamantepal/Documents/programs/Breakthrough Tech AI MIT/AI Studio/Customer_Sentiment_Analysis/Datasets/LeadsData.csv',sep =\"\\t\" )\n",
    "availability_data = pd.read_csv('/Users/aryamantepal/Documents/programs/Breakthrough Tech AI MIT/AI Studio/Customer_Sentiment_Analysis/Datasets/AvailabilityData.csv', sep=\"\\t\")\n",
    "\n",
    "def get_personalized_outreach_timing(company_name):\n",
    "    company_feedback = feedback_data[feedback_data['Company Name'] == company_name]\n",
    "    \n",
    "    avg_sentiment = company_feedback['combined_sentiment'].mean()\n",
    "    avg_rating = company_feedback['Rating'].mean()\n",
    "    \n",
    "    company_availability = availability_data[availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)]\n",
    "    \n",
    "    company_lead = leads_data[leads_data['Company Name'] == company_name]\n",
    "    \n",
    "    outreach_recommendation = {\n",
    "        'Company Name': company_name,\n",
    "        'Average Sentiment': avg_sentiment,\n",
    "        'Average Rating': avg_rating,\n",
    "        'Sentiment Quality': 'High' if avg_sentiment > 7 else 'Medium' if avg_sentiment > 5 else 'Low',\n",
    "        'Best Outreach Window': None,\n",
    "        'Recommended Approach': None\n",
    "    }\n",
    "    \n",
    "    if not company_availability.empty:\n",
    "        least_downtime_periods = company_availability.nsmallest(3, 'Availability DownTime Duration in hours')\n",
    "        \n",
    "        outreach_recommendation['Best Outreach Window'] = {\n",
    "            'Dates': least_downtime_periods['Date'].tolist(),\n",
    "            'Avg Downtime': least_downtime_periods['Availability DownTime Duration in hours'].mean()\n",
    "        }\n",
    "    \n",
    "    if outreach_recommendation['Sentiment Quality'] == 'High':\n",
    "        recommendation = \"Immediate outreach recommended. High sentiment indicates strong potential.\"\n",
    "    elif company_lead['Status'].values[0] in ['Open', 'Proposal Sent']:\n",
    "        recommendation = \"Gentle follow-up suggested. Maintain existing communication momentum.\"\n",
    "    else:\n",
    "        recommendation = \"Cautious approach needed. Prepare comprehensive value proposition.\"\n",
    "    \n",
    "    outreach_recommendation['Recommended Approach'] = recommendation\n",
    "    \n",
    "    return outreach_recommendation\n",
    "\n",
    "def analyze_multiple_companies(companies):\n",
    "    results = []\n",
    "    for company in companies:\n",
    "        result = get_personalized_outreach_timing(company)\n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "companies_to_analyze = leads_data['Company Name'].unique()\n",
    "company_outreach_analysis = analyze_multiple_companies(companies_to_analyze)\n",
    "\n",
    "company_outreach_analysis.to_csv('company_outreach_analysis.csv', index=False)\n",
    "print(company_outreach_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
      "/var/folders/rx/q5w9l9sd7zq8l0t_p73qg_l00000gn/T/ipykernel_57203/1722683557.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Company  Days Since Last Feedback Current Lead Status  \\\n",
      "0         A+ Electronics                       218         Closed-Lost   \n",
      "1         A+ Investments                       223       Proposal Sent   \n",
      "2       A Plus Lawn Care                       218          Closed-Won   \n",
      "3            Access Asia                       220         Closed-Lost   \n",
      "4     Accord Investments                       221                 New   \n",
      "...                  ...                       ...                 ...   \n",
      "4478              iTunes                       218        Disqualified   \n",
      "4479               iiNet                       218        Disqualified   \n",
      "4480                resQ                       218           Contacted   \n",
      "4481         ÃcomarchÃ©                       220           Reengaged   \n",
      "4482                ÃBB                       222           Nurturing   \n",
      "\n",
      "     Last Contact Date Optimal Outreach Window         Recommended Action  \n",
      "0           2024-03-29              2024-12-12  Proactive outreach needed  \n",
      "1           2024-04-14              2024-12-12  Proactive outreach needed  \n",
      "2           2024-01-07              2024-12-12  Proactive outreach needed  \n",
      "3           2024-01-18              2024-12-12  Proactive outreach needed  \n",
      "4           2024-03-13              2024-12-12  Proactive outreach needed  \n",
      "...                ...                     ...                        ...  \n",
      "4478        2024-02-29              2024-12-12  Proactive outreach needed  \n",
      "4479        2024-04-01              2024-12-12  Proactive outreach needed  \n",
      "4480        2024-04-19              2024-12-12  Proactive outreach needed  \n",
      "4481        2024-02-03              2024-12-12  Proactive outreach needed  \n",
      "4482        2024-02-21              2024-12-12  Proactive outreach needed  \n",
      "\n",
      "[4483 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "\n",
    "def determine_precise_outreach_time(company_name):\n",
    "    company_feedback = feedback_data[feedback_data['Company Name'] == company_name]\n",
    "    \n",
    "    company_lead = leads_data[leads_data['Company Name'] == company_name]\n",
    "    \n",
    "    company_availability = availability_data[\n",
    "        availability_data['Regions Affected'].str.contains(company_name, case=False, na=False)\n",
    "    ]\n",
    "    \n",
    "    if not company_feedback.empty:\n",
    "        most_recent_feedback = company_feedback['Timestamp'].max()\n",
    "        \n",
    "        days_since_last_feedback = (pd.Timestamp.now() - pd.Timestamp(most_recent_feedback)).days\n",
    "        \n",
    "        feedback_frequency = company_feedback.groupby(pd.to_datetime(company_feedback['Timestamp']).dt.to_period('M')).size()\n",
    "        \n",
    "        peak_feedback_months = feedback_frequency[feedback_frequency == feedback_frequency.max()]\n",
    "    \n",
    "    if not company_lead.empty:\n",
    "        current_status = company_lead['Status'].values[0]\n",
    "        last_contact_date = company_lead['Date'].values[0]\n",
    "    \n",
    "    optimal_timing = {\n",
    "        'Company': company_name,\n",
    "        'Days Since Last Feedback': days_since_last_feedback,\n",
    "        'Current Lead Status': current_status,\n",
    "        'Last Contact Date': last_contact_date,\n",
    "        'Optimal Outreach Window': None,\n",
    "        'Recommended Action': None\n",
    "    }\n",
    "    \n",
    "    if days_since_last_feedback > 30:\n",
    "        optimal_date = pd.Timestamp.now() + timedelta(days=7)  \n",
    "        optimal_timing['Optimal Outreach Window'] = optimal_date.strftime('%Y-%m-%d')\n",
    "        optimal_timing['Recommended Action'] = \"Proactive outreach needed\"\n",
    "    \n",
    "    elif current_status in ['Open', 'Proposal Sent']:\n",
    "        optimal_date = pd.Timestamp.now() + timedelta(days=3)  \n",
    "        optimal_timing['Optimal Outreach Window'] = optimal_date.strftime('%Y-%m-%d')\n",
    "        optimal_timing['Recommended Action'] = \"Gentle follow-up\"\n",
    "    \n",
    "    else:\n",
    "        optimal_date = pd.Timestamp.now() + timedelta(days=10)  \n",
    "        optimal_timing['Optimal Outreach Window'] = optimal_date.strftime('%Y-%m-%d')\n",
    "        optimal_timing['Recommended Action'] = \"Strategic reengagement\"\n",
    "    \n",
    "    return optimal_timing\n",
    "\n",
    "companies = leads_data['Company Name'].unique()\n",
    "timing_results = [determine_precise_outreach_time(company) for company in companies]\n",
    "\n",
    "timing_df = pd.DataFrame(timing_results)\n",
    "timing_df.to_csv('precise_outreach_timing.csv', index=False)\n",
    "\n",
    "print(timing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company': 'A+ Electronics', 'Days Since Last Feedback': 218, 'Current Lead Status': 'Closed-Lost', 'Last Contact Date': '2024-03-29', 'Optimal Outreach Window': '2024-12-12', 'Recommended Action': 'Proactive outreach needed'}\n"
     ]
    }
   ],
   "source": [
    "company_name = \"A+ Electronics\"\n",
    "outreach_timing = determine_precise_outreach_time(company_name)\n",
    "print(outreach_timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Immediate outreach recommended. High sentiment indicates strong potential.',\n",
       "       'Cautious approach needed. Prepare comprehensive value proposition.',\n",
       "       'Gentle follow-up suggested. Maintain existing communication momentum.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_outreach_analysis['Recommended Approach'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company Name': 'Awthentikz', 'Average Sentiment': 6.804280626473981, 'Average Rating': 5.190476190476191, 'Sentiment Quality': 'Medium', 'Best Outreach Window': None, 'Recommended Approach': 'Cautious approach needed. Prepare comprehensive value proposition.'}\n"
     ]
    }
   ],
   "source": [
    "company_name = \"Awthentikz\"\n",
    "outreach_timing = get_personalized_outreach_timing(company_name)\n",
    "print(outreach_timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Company  Employee Count               Regions  \\\n",
      "0         A+ Electronics           30958    USA, India, Europe   \n",
      "1         A+ Investments           26677                Europe   \n",
      "2       A Plus Lawn Care           34069                 China   \n",
      "3            Access Asia           31936    USA, India, Europe   \n",
      "4     Accord Investments           17903                 India   \n",
      "...                  ...             ...                   ...   \n",
      "4478              iTunes           16161                 China   \n",
      "4479               iiNet           19353  Japan, China, Europe   \n",
      "4480                resQ           34661                   USA   \n",
      "4481         ÃcomarchÃ©            8396                 India   \n",
      "4482                ÃBB           33750                 India   \n",
      "\n",
      "      Days Since Last Feedback Current Lead Status Last Contact Date  \\\n",
      "0                          218         Closed-Lost        2024-03-29   \n",
      "1                          223       Proposal Sent        2024-04-14   \n",
      "2                          218          Closed-Won        2024-01-07   \n",
      "3                          220         Closed-Lost        2024-01-18   \n",
      "4                          221                 New        2024-03-13   \n",
      "...                        ...                 ...               ...   \n",
      "4478                       218        Disqualified        2024-02-29   \n",
      "4479                       218        Disqualified        2024-04-01   \n",
      "4480                       218           Contacted        2024-04-19   \n",
      "4481                       220           Reengaged        2024-02-03   \n",
      "4482                       222           Nurturing        2024-02-21   \n",
      "\n",
      "     Optimal Outreach Window             Recommended Action  \\\n",
      "0                 2024-12-06         Potential Resurrection   \n",
      "1                 2024-12-17                Gentle Reminder   \n",
      "2                 2024-12-19          Maintain Relationship   \n",
      "3                 2024-12-06         Potential Resurrection   \n",
      "4                 2024-12-10               Initial Outreach   \n",
      "...                      ...                            ...   \n",
      "4478              2024-12-06                   Low Priority   \n",
      "4479              2024-12-06                   Low Priority   \n",
      "4480              2024-12-14  Initial Relationship Building   \n",
      "4481              2024-12-13      Renewed Interest Tracking   \n",
      "4482              2024-12-09                     Soft Touch   \n",
      "\n",
      "                                    Availability Impact  \n",
      "0     Avg Downtime: 10.87 hrs, Customers Affected: 3...  \n",
      "1     Avg Downtime: 11.05 hrs, Customers Affected: 1...  \n",
      "2     Avg Downtime: 12.04 hrs, Customers Affected: 1...  \n",
      "3     Avg Downtime: 10.87 hrs, Customers Affected: 3...  \n",
      "4     Avg Downtime: 11.33 hrs, Customers Affected: 1...  \n",
      "...                                                 ...  \n",
      "4478  Avg Downtime: 12.04 hrs, Customers Affected: 1...  \n",
      "4479  Avg Downtime: 10.85 hrs, Customers Affected: 3...  \n",
      "4480  Avg Downtime: 9.71 hrs, Customers Affected: 12...  \n",
      "4481  Avg Downtime: 11.33 hrs, Customers Affected: 1...  \n",
      "4482  Avg Downtime: 11.33 hrs, Customers Affected: 1...  \n",
      "\n",
      "[4483 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "def determine_precise_outreach_time(company_name, leads_data, feedback_data, availability_data, company_details):\n",
    "    company_feedback = feedback_data[feedback_data['Company Name'] == company_name]\n",
    "    company_lead = leads_data[leads_data['Company Name'] == company_name]\n",
    "    company_info = company_details[company_details['Company Name'] == company_name]\n",
    "    \n",
    "    company_regions = company_info['Region Served'].values[0].split(', ')\n",
    "    company_availability = availability_data[\n",
    "        availability_data['Regions Affected'].apply(\n",
    "            lambda x: any(region in x.split(', ') for region in company_regions)\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    optimal_timing = {\n",
    "        'Company': company_name,\n",
    "        'Employee Count': company_info['Employee Count'].values[0] if not company_info.empty else 'N/A',\n",
    "        'Regions': company_info['Region Served'].values[0] if not company_info.empty else 'N/A',\n",
    "        'Days Since Last Feedback': None,\n",
    "        'Current Lead Status': None,\n",
    "        'Last Contact Date': None,\n",
    "        'Optimal Outreach Window': None,\n",
    "        'Recommended Action': None,\n",
    "        'Availability Impact': None\n",
    "    }\n",
    "    \n",
    "    if not company_lead.empty:\n",
    "        current_status = company_lead['Status'].values[0]\n",
    "        last_contact_date = company_lead['Date'].values[0]\n",
    "        \n",
    "        optimal_timing['Current Lead Status'] = current_status\n",
    "        optimal_timing['Last Contact Date'] = last_contact_date\n",
    "    \n",
    "    if not company_feedback.empty:\n",
    "        most_recent_feedback = company_feedback['Timestamp'].max()\n",
    "        days_since_last_feedback = (pd.Timestamp.now() - pd.Timestamp(most_recent_feedback)).days\n",
    "        \n",
    "        optimal_timing['Days Since Last Feedback'] = days_since_last_feedback\n",
    "    \n",
    "    if not company_availability.empty:\n",
    "        avg_downtime = company_availability['Availability DownTime Duration in hours'].mean()\n",
    "        total_customers_affected = company_availability['Count of Customers Affected'].sum()\n",
    "        \n",
    "        optimal_timing['Availability Impact'] = f\"Avg Downtime: {avg_downtime:.2f} hrs, Customers Affected: {total_customers_affected}\"\n",
    "    \n",
    "    status_priority = {\n",
    "        'Closed-Won': (1, \"Maintain Relationship\"),\n",
    "        'Negotiation': (2, \"Immediate Follow-up\"),\n",
    "        'Proposal Sent': (3, \"Gentle Reminder\"),\n",
    "        'Qualified': (4, \"Strategic Nurturing\"),\n",
    "        'Warm ': (5, \"Continued Engagement\"),\n",
    "        'Contacted': (6, \"Initial Relationship Building\"),\n",
    "        'Reengaged': (7, \"Renewed Interest Tracking\"),\n",
    "        'Referral': (8, \"High Potential Pursuit\"),\n",
    "        'In Progress': (9, \"Ongoing Monitoring\"),\n",
    "        'New': (10, \"Initial Outreach\"),\n",
    "        'Nurturing': (11, \"Soft Touch\"),\n",
    "        'On-hold': (12, \"Periodic Check-in\"),\n",
    "        'Cold': (13, \"Strategic Reactivation\"),\n",
    "        'Closed-Lost': (14, \"Potential Resurrection\"),\n",
    "        'Disqualified': (15, \"Low Priority\")\n",
    "    }\n",
    "    \n",
    "    if current_status in status_priority:\n",
    "        priority, action = status_priority[current_status]\n",
    "        \n",
    "        days_offset = max(1, 15 - priority)\n",
    "        optimal_date = pd.Timestamp.now() + timedelta(days=days_offset)\n",
    "        \n",
    "        optimal_timing['Optimal Outreach Window'] = optimal_date.strftime('%Y-%m-%d')\n",
    "        optimal_timing['Recommended Action'] = action\n",
    "    \n",
    "    return optimal_timing\n",
    "\n",
    "def analyze_outreach_timing(leads_data, feedback_data, availability_data, company_details):\n",
    "    companies = leads_data['Company Name'].unique()\n",
    "    \n",
    "    timing_results = [\n",
    "        determine_precise_outreach_time(\n",
    "            company, \n",
    "            leads_data, \n",
    "            feedback_data, \n",
    "            availability_data, \n",
    "            company_details\n",
    "        ) for company in companies\n",
    "    ]\n",
    "    \n",
    "    timing_df = pd.DataFrame(timing_results)\n",
    "    timing_df.to_csv('precise_outreach_timing.csv', index=False)\n",
    "    return timing_df\n",
    "\n",
    "\n",
    "feedback_data = pd.read_csv('/Users/aryamantepal/Documents/programs/Breakthrough Tech AI MIT/AI Studio/Customer_Sentiment_Analysis/clean-data/feedback_data_with_sentiment.csv', sep=\",\")\n",
    "leads_data = pd.read_csv('/Users/aryamantepal/Documents/programs/Breakthrough Tech AI MIT/AI Studio/Customer_Sentiment_Analysis/Datasets/LeadsData.csv',sep =\"\\t\" )\n",
    "availability_data = pd.read_csv('/Users/aryamantepal/Documents/programs/Breakthrough Tech AI MIT/AI Studio/Customer_Sentiment_Analysis/Datasets/AvailabilityData.csv', sep=\"\\t\")\n",
    "company_details = pd.read_csv('/Users/aryamantepal/Documents/programs/Breakthrough Tech AI MIT/AI Studio/Customer_Sentiment_Analysis/Datasets/CompanyDetails.csv', sep = \"\\t\")\n",
    "\n",
    "result = analyze_outreach_timing(leads_data, feedback_data, availability_data, company_details)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Company': 'A+ Investments', 'Regions': 'Europe', 'Current Status': 'Proposal Sent', 'Last Contact': '2024-04-14', 'Recommended Outreach': '2024-12-08'}\n"
     ]
    }
   ],
   "source": [
    "def get_company_outreach_time(company_name, leads_df, company_details_df, availability_df):\n",
    "    \"\"\"\n",
    "    Get precise outreach timing for a specific company\n",
    "    \n",
    "    Args:\n",
    "        company_name (str): Target company name\n",
    "        leads_df (pd.DataFrame): Leads data\n",
    "        company_details_df (pd.DataFrame): Company details\n",
    "        availability_df (pd.DataFrame): Availability data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Outreach timing recommendations\n",
    "    \"\"\"\n",
    "    avoid_statuses = ['Closed-Lost', 'Disqualified', 'Cold']\n",
    "    \n",
    "    company_details = company_details_df[company_details_df['Company Name'] == company_name]\n",
    "    if company_details.empty:\n",
    "        return {'Company': company_name, 'Error': 'Company not found'}\n",
    "    \n",
    "    company_regions = company_details['Region Served'].values[0].split(', ')\n",
    "    \n",
    "    company_leads = leads_df[leads_df['Company Name'] == company_name]\n",
    "    \n",
    "    if company_leads.empty:\n",
    "        return {'Company': company_name, 'Error': 'No leads found'}\n",
    "    \n",
    "    latest_lead = company_leads.sort_values('Date', ascending=False).iloc[0]\n",
    "    \n",
    "    if latest_lead['Status'] in avoid_statuses:\n",
    "        return {\n",
    "            'Company': company_name,\n",
    "            'Status': latest_lead['Status'],\n",
    "            'Recommendation': 'No outreach recommended'\n",
    "        }\n",
    "    \n",
    "    region_availability = availability_df[\n",
    "        availability_df['Regions Affected'].apply(\n",
    "            lambda x: any(region in x.split(', ') for region in company_regions)\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    status_timing = {\n",
    "        'Negotiation': timedelta(days=1),\n",
    "        'Proposal Sent': timedelta(days=3),\n",
    "        'Qualified': timedelta(days=5),\n",
    "        'Warm ': timedelta(days=7),\n",
    "        'New': timedelta(days=10),\n",
    "        'Contacted': timedelta(days=14)\n",
    "    }\n",
    "    \n",
    "    outreach_delta = status_timing.get(latest_lead['Status'], timedelta(days=7))\n",
    "    \n",
    "    recommended_outreach = pd.Timestamp.now() + outreach_delta\n",
    "    \n",
    "    return {\n",
    "        'Company': company_name,\n",
    "        'Regions': ', '.join(company_regions),\n",
    "        'Current Status': latest_lead['Status'],\n",
    "        'Last Contact': latest_lead['Date'],\n",
    "        'Recommended Outreach': recommended_outreach.strftime('%Y-%m-%d')\n",
    "    }\n",
    "\n",
    "result = get_company_outreach_time(\n",
    "    'A+ Investments', \n",
    "    leads_data, \n",
    "    company_details, \n",
    "    availability_data\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salesforce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
